{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  onehot__SEX_1.0  onehot__SEX_2.0  onehot__SEX_3.0  \\\n",
      "0           0              0.0              1.0              0.0   \n",
      "1           1              1.0              0.0              0.0   \n",
      "2           2              1.0              0.0              0.0   \n",
      "3           3              1.0              0.0              0.0   \n",
      "4           4              0.0              1.0              0.0   \n",
      "\n",
      "   onehot__ETHNICITY_1.0  onehot__ETHNICITY_2.0  onehot__TBIMIDLINESHIFT_1.0  \\\n",
      "0                    0.0                    1.0                          0.0   \n",
      "1                    1.0                    0.0                          0.0   \n",
      "2                    0.0                    1.0                          0.0   \n",
      "3                    0.0                    1.0                          0.0   \n",
      "4                    0.0                    1.0                          0.0   \n",
      "\n",
      "   onehot__TBIMIDLINESHIFT_2.0  onehot__TBIMIDLINESHIFT_3.0  \\\n",
      "0                          1.0                          0.0   \n",
      "1                          1.0                          0.0   \n",
      "2                          1.0                          0.0   \n",
      "3                          1.0                          0.0   \n",
      "4                          1.0                          0.0   \n",
      "\n",
      "   onehot__TEACHINGSTATUS_1.0  ...  scaler__RESPIRATORYRATE  \\\n",
      "0                         0.0  ...                 1.052371   \n",
      "1                         0.0  ...                -1.052626   \n",
      "2                         0.0  ...                -0.210627   \n",
      "3                         0.0  ...                -0.210627   \n",
      "4                         0.0  ...                -0.210627   \n",
      "\n",
      "   scaler__PULSEOXIMETRY  scaler__HEIGHT  scaler__WEIGHT  scaler__TOTALGCS  \\\n",
      "0               0.361127       -3.117664       -2.272820          0.325218   \n",
      "1               0.511366       -0.132069       -0.838981          0.325218   \n",
      "2               0.361127        0.329500       -0.815281          0.325218   \n",
      "3               0.511366       -1.540148       -1.640825          0.325218   \n",
      "4               0.511366       -2.971598       -2.027922          0.325218   \n",
      "\n",
      "   scaler__HOSPITALARRIVALHRS  scaler__HOSPITALARRIVALDAYS  \\\n",
      "0               -9.088105e-18                    -0.021071   \n",
      "1               -9.088105e-18                    -0.021071   \n",
      "2               -9.088105e-18                    -0.021071   \n",
      "3               -9.088105e-18                    -0.021071   \n",
      "4               -9.088105e-18                    -0.021071   \n",
      "\n",
      "   scaler__TBIHIGHESTTOTALGCS  scaler__ISS  transfusion  \n",
      "0                9.919297e-01     0.838320          0.0  \n",
      "1                9.919297e-01    -0.032457          0.0  \n",
      "2               -2.524544e-15    -1.027631          0.0  \n",
      "3               -2.524544e-15    -0.530044          0.0  \n",
      "4                9.919297e-01    -0.530044          0.0  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "(1232956, 81)\n"
     ]
    }
   ],
   "source": [
    "# get trauma_preprocessed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "trauma_preprocessed = pd.read_csv('trauma_preprocessed_final.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm import\n",
    "print(trauma_preprocessed.head())\n",
    "print(trauma_preprocessed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "Will first use a small model trained on 10,000 units before full set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 81)\n"
     ]
    }
   ],
   "source": [
    "# making a small dataset to test models easier\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows to selecte\n",
    "n = 10000\n",
    "\n",
    "# Randomly select n rows\n",
    "trauma_preprocessed_small= trauma_preprocessed.sample(n=n, random_state=42)\n",
    "\n",
    "# Display the first few rows of the sampled DataFrame\n",
    "print(trauma_preprocessed_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Define the preprocessing steps for categorical and continuous features\n",
    "\n",
    "# temp solution just drop the cat features. dont seem physiologically important, lets prototype this\n",
    "# there are several continuous vars that will need to be binarized or made into categoricals though\n",
    "\n",
    "\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = trauma_preprocessed_small.drop('transfusion', axis=1)\n",
    "y = trauma_preprocessed_small['transfusion']\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning\n",
    "Now that you got some good pre-processing done, you will need to do the model fine tuning. look at what each of them can do, and what is significant, etc. basically find the one that works the best given all this data you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding label__ETHNICITY with p-value 0.9999999999998618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding label__PROTDEV_AIRBAG_PRESENT with p-value 0.9813107137343111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding onehot__TBIMIDLINESHIFT_2.0 with p-value 0.9999997481068926\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding onehot__TEACHINGSTATUS_1.0 with p-value 0.9999986076695293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding onehot__ETHNICITY_2.0 with p-value 0.9999986514544464\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding onehot__SEX_1.0 with p-value 0.999999229140904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.226092\n",
      "         Iterations: 35\n",
      "Excluding onehot__SEX_3.0 with p-value 0.9979239033663566\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226104\n",
      "         Iterations 8\n",
      "Excluding label__PROTDEV_HELMET with p-value 0.9477956396169486\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226105\n",
      "         Iterations 8\n",
      "Excluding scaler__HOSPITALARRIVALDAYS with p-value 0.8754347874998852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226107\n",
      "         Iterations 8\n",
      "Excluding label__RACE_UK with p-value 0.867583681714607\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226109\n",
      "         Iterations 8\n",
      "Excluding label__RACEOTHER with p-value 0.8709785088771107\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226111\n",
      "         Iterations 8\n",
      "Excluding label__PREHOSPITALCARDIACARREST with p-value 0.8437691324610596\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226113\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_METHAMPHETAMINE with p-value 0.8424189157477222\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226116\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_NONE with p-value 0.8581889865230554\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226118\n",
      "         Iterations 8\n",
      "Excluding scaler__RESPIRATORYRATE with p-value 0.7899055362066887\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226124\n",
      "         Iterations 8\n",
      "Excluding label__PROTDEV_SHOULDER_BELT with p-value 0.7773327717698076\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226129\n",
      "         Iterations 8\n",
      "Excluding label__AIRBAG_NOTDEPLOYED with p-value 0.7772638330757526\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226135\n",
      "         Iterations 8\n",
      "Excluding label__AIRBAG_DEPLOYED_NA with p-value 0.9111731308985445\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226136\n",
      "         Iterations 8\n",
      "Excluding label__AIRBAG_DEPLOYED_UK with p-value 0.7942972293114575\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226141\n",
      "         Iterations 8\n",
      "Excluding label__AIRBAG_DEPLOYED_FRNT with p-value 0.8066596191541049\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226145\n",
      "         Iterations 8\n",
      "Excluding label__WORKRELATED with p-value 0.7431472179412855\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226153\n",
      "         Iterations 8\n",
      "Excluding label__ALCOHOLSCREEN with p-value 0.7054519286123334\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226163\n",
      "         Iterations 8\n",
      "Excluding scaler__TBIHIGHESTTOTALGCS with p-value 0.6915892231534679\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226174\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_BENZODIAZEPINES with p-value 0.6882272538389527\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226185\n",
      "         Iterations 8\n",
      "Excluding scaler__HEIGHT with p-value 0.6701466789217818\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226199\n",
      "         Iterations 8\n",
      "Excluding onehot__ETHNICITY_1.0 with p-value 0.6372983857397686\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226215\n",
      "         Iterations 8\n",
      "Excluding label__RESPIRATORYASSISTANCE with p-value 0.6151318800519235\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226233\n",
      "         Iterations 8\n",
      "Excluding label__HOSPITALTYPE with p-value 0.6146612842657253\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226251\n",
      "         Iterations 8\n",
      "Excluding label__GCSQ_SEDATEDPARALYZED with p-value 0.5870389873535726\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226272\n",
      "         Iterations 8\n",
      "Excluding label__PEDIATRICVERIFICATIONLEVEL with p-value 0.5483800170732316\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226297\n",
      "         Iterations 8\n",
      "Excluding onehot__TBIMIDLINESHIFT_1.0 with p-value 0.5336090374838385\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226325\n",
      "         Iterations 8\n",
      "Excluding label__PROTDEV_LAP_BELT with p-value 0.5357501025569886\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226353\n",
      "         Iterations 8\n",
      "Excluding label__PROTDEV_UK with p-value 0.5615243440742996\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226376\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_OPIOID with p-value 0.5488639477776409\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226401\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_NOTTESTED with p-value 0.5357598814090014\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226428\n",
      "         Iterations 8\n",
      "Excluding label__ASIAN with p-value 0.5144302244261973\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226459\n",
      "         Iterations 8\n",
      "Excluding scaler__PULSEOXIMETRY with p-value 0.5317199781390894\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226487\n",
      "         Iterations 8\n",
      "Excluding label__SUPPLEMENTALOXYGEN with p-value 0.5393889580248518\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226514\n",
      "         Iterations 8\n",
      "Excluding label__PMGCSQ_SEDATEDPARALYZED with p-value 0.5192038965303658\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226544\n",
      "         Iterations 8\n",
      "Excluding label__PMGCSQ_VALID with p-value 0.49055009783240466\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226578\n",
      "         Iterations 8\n",
      "Excluding label__AIRBAG_DEPLOYED_SIDE with p-value 0.48601054504122787\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226612\n",
      "         Iterations 8\n",
      "Excluding scaler__WEIGHT with p-value 0.36576810121472125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226670\n",
      "         Iterations 8\n",
      "Excluding label__HOMERESIDENCE_UK with p-value 0.3395547184128488\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226733\n",
      "         Iterations 8\n",
      "Excluding label__HOMERESIDENCE_NA with p-value 0.7043885882986256\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226743\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_AMPHETAMINE with p-value 0.3340295872592516\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226813\n",
      "         Iterations 8\n",
      "Excluding label__TM_PRIVPUBVEHWALKIN with p-value 0.3027935562120191\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226895\n",
      "         Iterations 8\n",
      "Excluding label__TM_NA with p-value 0.8203757275889726\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226899\n",
      "         Iterations 8\n",
      "Excluding label__TM_UK with p-value 0.7570021498389568\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226906\n",
      "         Iterations 8\n",
      "Excluding label__Bedsize with p-value 0.25699966151048226\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.226998\n",
      "         Iterations 8\n",
      "Excluding label__GCSQ_INTUBATED with p-value 0.24989002413311634\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227112\n",
      "         Iterations 8\n",
      "Excluding label__GCSQ_VALID with p-value 0.2705388325035806\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227199\n",
      "         Iterations 8\n",
      "Excluding scaler__TOTALGCS with p-value 0.3508425481480346\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227261\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_CANNABINOID with p-value 0.2225951138717953\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227371\n",
      "         Iterations 8\n",
      "Excluding label__BLACK with p-value 0.24955083667593048\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227466\n",
      "         Iterations 8\n",
      "Excluding label__STATEPEDIATRICDESIGNATION with p-value 0.22860245194943618\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227568\n",
      "         Iterations 8\n",
      "Excluding label__PROTDEV_NONE with p-value 0.22567708412546084\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227675\n",
      "         Iterations 8\n",
      "Excluding label__VERIFICATIONLEVEL with p-value 0.1936829928552346\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227794\n",
      "         Iterations 8\n",
      "Excluding label__STATEDESIGNATION with p-value 0.2685890466889471\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.227885\n",
      "         Iterations 8\n",
      "Excluding onehot__SEX_2.0 with p-value 0.1845761975718846\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228010\n",
      "         Iterations 8\n",
      "Excluding label__TBIPUPILLARYRESPONSE with p-value 0.16130146275155632\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228154\n",
      "         Iterations 8\n",
      "Excluding label__GCSQ_UK with p-value 0.12493227637632988\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228310\n",
      "         Iterations 8\n",
      "Excluding label__DRGSCR_COCAINE with p-value 0.11299961603681272\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228513\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228513\n",
      "         Iterations 8\n",
      "\n",
      "Final model after stepwise selection:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            transfusion   No. Observations:                 7000\n",
      "Model:                          Logit   Df Residuals:                     6981\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 11 Nov 2024   Pseudo R-squ.:                  0.2124\n",
      "Time:                        12:40:33   Log-Likelihood:                -1599.6\n",
      "converged:                       True   LL-Null:                       -2030.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.402e-171\n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                           -2.3791      0.235    -10.137      0.000      -2.839      -1.919\n",
      "Unnamed: 0                   -2.964e-07   1.36e-07     -2.183      0.029   -5.63e-07   -3.03e-08\n",
      "onehot__TBIMIDLINESHIFT_3.0     -1.9907      0.667     -2.986      0.003      -3.297      -0.684\n",
      "onehot__TEACHINGSTATUS_5.0      -0.1974      0.106     -1.857      0.063      -0.406       0.011\n",
      "onehot__TEACHINGSTATUS_6.0      -0.4815      0.155     -3.109      0.002      -0.785      -0.178\n",
      "label__WHITE                    -0.2756      0.109     -2.536      0.011      -0.489      -0.063\n",
      "label__TRANSPORTMODE            -0.2122      0.058     -3.640      0.000      -0.326      -0.098\n",
      "label__TM_GROUNDAMBULANCE        0.3811      0.146      2.613      0.009       0.095       0.667\n",
      "label__INTERFACILITYTRANSFER     0.4515      0.133      3.393      0.001       0.191       0.712\n",
      "label__PMGCSQ_INTUBATED          0.7744      0.231      3.347      0.001       0.321       1.228\n",
      "label__PMGCSQ_NA                 0.6052      0.119      5.097      0.000       0.372       0.838\n",
      "label__HIGHESTACTIVATION        -1.0341      0.116     -8.950      0.000      -1.261      -0.808\n",
      "label__PRIMARYMETHODPAYMENT      0.0696      0.035      1.960      0.050   -4.49e-06       0.139\n",
      "scaler__AgeYears                 0.5231      0.062      8.490      0.000       0.402       0.644\n",
      "scaler__SBP                     -0.4212      0.048     -8.862      0.000      -0.514      -0.328\n",
      "scaler__PULSERATE                0.3387      0.043      7.835      0.000       0.254       0.423\n",
      "scaler__TEMPERATURE             -0.0644      0.032     -2.000      0.045      -0.127      -0.001\n",
      "scaler__HOSPITALARRIVALHRS       1.8039      0.899      2.007      0.045       0.042       3.566\n",
      "scaler__ISS                      0.5864      0.045     12.951      0.000       0.498       0.675\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add a constant (intercept) to the model\n",
    "X_train_lr = sm.add_constant(X_train)\n",
    "\n",
    "\n",
    "def stepwise_logistic_regression(X, y, threshold_in=0.05, threshold_out=0.10):\n",
    "    \"\"\"\n",
    "    Perform stepwise logistic regression using AIC as the criterion for backward elimination.\n",
    "    \"\"\"\n",
    "    initial_features = X.columns.tolist()  # List of all columns (features)\n",
    "    while True:\n",
    "        model = sm.Logit(y, X[initial_features])\n",
    "        result = model.fit()\n",
    "        \n",
    "        # Get the highest p-value predictor\n",
    "        p_values = result.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value > threshold_out:  # If the p-value is higher than the threshold, remove it\n",
    "            excluded_feature = p_values.idxmax()  # Feature with the highest p-value\n",
    "            print(f\"Excluding {excluded_feature} with p-value {max_p_value}\")\n",
    "            initial_features.remove(excluded_feature)  # Remove the feature from the list\n",
    "        else:\n",
    "            break  # If no feature can be removed, stop the process\n",
    "    \n",
    "    # Final model\n",
    "    final_model = sm.Logit(y, X[initial_features])\n",
    "    final_result = final_model.fit()\n",
    "    \n",
    "    print(\"\\nFinal model after stepwise selection:\")\n",
    "    print(final_result.summary())\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "# Perform stepwise logistic regression\n",
    "final_model = stepwise_logistic_regression(X_train_lr, y_train)\n",
    "\n",
    "\n",
    "# result = final_model.fit()\n",
    "\n",
    "# # Print the p-values of each predictor\n",
    "# print(\"P-values for each predictor:\")\n",
    "# print(result.pvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[2695   36]\n",
      " [ 214   55]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Optionally, you can also print the accuracy and other metrics\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, predictions)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Print classification report\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# using final model to make predictions\n",
    "\n",
    "# List of selected features (columns) after stepwise selection\n",
    "selected_features = final_model.model.exog_names  # Get the names of the selected features from the final model\n",
    "selected_features.remove('const')\n",
    "\n",
    "# Make sure to drop the constant column if it's present in X_test (it should be)\n",
    "X_test_selected = X_test[selected_features]\n",
    "X_test_selected = sm.add_constant(X_test_selected) # add const back\n",
    "\n",
    "# Predict on the test data using the final model with only selected features\n",
    "predictions_prob = final_model.predict(X_test_selected)  # Get predicted probabilities\n",
    "\n",
    "# Convert probabilities to binary class predictions (0 or 1)\n",
    "predictions = (predictions_prob >= 0.5).astype(int)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9167\n",
      "Precision: 0.6044\n",
      "Recall (Sensitivity): 0.2045\n",
      "Specificity: 0.9868\n",
      "F1-Score: 0.3056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0  # Avoid division by zero\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0      # Avoid division by zero\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "sensitivity = recall  # Sensitivity is the same as Recall\n",
    "specificity = TN / (TN + FP) if (TN + FP) != 0 else 0   # Avoid division by zero\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['scaler__ISS', 'label__HIGHESTACTIVATION', 'scaler__AgeYears', 'scaler__SBP', 'scaler__PULSERATE', 'label__PMGCSQ_NA', 'label__TRANSPORTMODE', 'label__PMGCSQ_INTUBATED', 'onehot__TBIMIDLINESHIFT_3.0', 'onehot__TEACHINGSTATUS_6.0', 'label__WHITE', 'label__INTERFACILITYTRANSFER', 'label__TM_GROUNDAMBULANCE', 'Unnamed: 0', 'scaler__TEMPERATURE', 'label__PRIMARYMETHODPAYMENT', 'onehot__TEACHINGSTATUS_1.0', 'label__DRGSCR_COCAINE', 'scaler__HOSPITALARRIVALHRS', 'label__GCSQ_UK', 'label__TBIPUPILLARYRESPONSE']\n",
      "Model Accuracy: 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# lets try stepwise logistic regression first\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "\n",
    "# Forward Stepwise Selection using AIC\n",
    "def forward_selection_aic(X, y):\n",
    "    remaining_features = X.columns.tolist()\n",
    "    selected_features = []\n",
    "    best_aic = np.inf  # Start with a very high AIC to ensure the first model improves it\n",
    "    \n",
    "    while remaining_features:\n",
    "        aic_with_added_feature = {}\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            features_temp = selected_features + [feature]\n",
    "            X_train_step = X[features_temp]\n",
    "            X_train_step = sm.add_constant(X_train_step)  # Add constant term (intercept)\n",
    "            model = sm.Logit(y, X_train_step)  # Logistic Regression model\n",
    "            result = model.fit(disp=0)  # disp=0 suppresses output\n",
    "            \n",
    "            # Record AIC for this model\n",
    "            aic_with_added_feature[feature] = result.aic\n",
    "        \n",
    "        # Find the feature that minimizes AIC\n",
    "        best_feature = min(aic_with_added_feature, key=aic_with_added_feature.get)\n",
    "        new_aic = aic_with_added_feature[best_feature]\n",
    "        \n",
    "        # If adding the best feature improves the AIC, add it to selected features\n",
    "        if new_aic < best_aic:\n",
    "            selected_features.append(best_feature)\n",
    "            best_aic = new_aic\n",
    "            remaining_features.remove(best_feature)\n",
    "        else:\n",
    "            break  # Stop if no improvement in AIC\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# Forward Stepwise Selection\n",
    "def stepwise_selection(X, y, model, threshold_in=0.1, threshold_out = 0.05):\n",
    "    initial_features = X.columns.tolist()\n",
    "    selected_features = []\n",
    "    \n",
    "    while len(initial_features) > 0:\n",
    "        # Fit the model with the current set of selected features\n",
    "        best_pval = 1\n",
    "        best_feature = None\n",
    "        for feature in initial_features:\n",
    "            # print(feature)\n",
    "            # Fit model with one additional feature\n",
    "            X_train_step = X[selected_features + [feature]]\n",
    "            model.fit(X_train_step, y)\n",
    "            # Using p-values from the logistic regression\n",
    "            pval = model.score(X_train_step, y)\n",
    "            if pval < best_pval:\n",
    "                print(feature, pval)\n",
    "                best_pval = pval\n",
    "                best_feature = feature\n",
    "        \n",
    "        # If the best feature is statistically significant, add it to the model\n",
    "        if best_pval < threshold_in:\n",
    "            selected_features.append(best_feature)\n",
    "            initial_features.remove(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Perform stepwise selection\n",
    "selected_features = forward_selection_aic(X_train, y_train)\n",
    "\n",
    "# Final model with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "log_reg.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "X_test_selected = X_test[selected_features]\n",
    "y_pred = log_reg.predict(X_test_selected)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "print(f\"Model Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.tolist()\n",
    "(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2704   27]\n",
      " [ 246   23]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95      2731\n",
      "        True       0.46      0.09      0.14       269\n",
      "\n",
      "    accuracy                           0.91      3000\n",
      "   macro avg       0.69      0.54      0.55      3000\n",
      "weighted avg       0.88      0.91      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2507  224]\n",
      " [ 174   95]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      2731\n",
      "           1       0.30      0.35      0.32       269\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.62      0.64      0.62      3000\n",
      "weighted avg       0.88      0.87      0.87      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now lets try decision tree classifiers\n",
    "from sklearn import tree\n",
    "\n",
    "y_binary = y.astype(int)\n",
    "\n",
    "X_train, X_test, y_train_b, y_test_b = train_test_split(X_scaled, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train_b)\n",
    "\n",
    "clf_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_b, clf_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_b, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 5\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_b)\n\u001b[0;32m      7\u001b[0m lr_pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_b' is not defined"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train_b)\n",
    "\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_b, lr_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_b, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2717   14]\n",
      " [ 228   41]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      2731\n",
      "           1       0.75      0.15      0.25       269\n",
      "\n",
      "    accuracy                           0.92      3000\n",
      "   macro avg       0.83      0.57      0.61      3000\n",
      "weighted avg       0.91      0.92      0.89      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train_b)\n",
    "\n",
    "# Predict and evaluate\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_b, rf_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_b, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2731    0]\n",
      " [ 269    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2731\n",
      "           1       0.00      0.00      0.00       269\n",
      "\n",
      "    accuracy                           0.91      3000\n",
      "   macro avg       0.46      0.50      0.48      3000\n",
      "weighted avg       0.83      0.91      0.87      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\micha\\anaconda3\\envs\\trauma\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# support vector machines\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the model\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train_b)\n",
    "\n",
    "# Predict and evaluate\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_b, svm_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_b, svm_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add: ridge regression, PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trauma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
