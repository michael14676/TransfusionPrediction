{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa8c6ab",
   "metadata": {},
   "source": [
    "# Most important variables\n",
    "The purpose of this notebook is to create a new dataset, one that is composed of only all the most important variables. This will be done to create a more condensed model that can be used to create predictions on the spot.\n",
    "\n",
    "## Data Loading\n",
    "First we compile all the data together. This will be taken from tqip_exploration.ipynb for the most part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e827b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4ae265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PUF Variable Formats.csv',\n",
       " 'PUF_AIS15TO05_CROSSWALK.csv',\n",
       " 'PUF_AISDIAGNOSIS.csv',\n",
       " 'PUF_AISDIAGNOSIS_LOOKUP.csv',\n",
       " 'PUF_Ecode_Lookup.csv',\n",
       " 'PUF_HOSPITALEVENTS.csv',\n",
       " 'PUF_ICDDIAGNOSIS.csv',\n",
       " 'PUF_ICDDIAGNOSIS_LOOKUP.csv',\n",
       " 'PUF_ICDPROCEDURE.csv',\n",
       " 'PUF_ICDPROCEDURE_LOOKUP.csv',\n",
       " 'PUF_PREEXISTINGCONDITIONS.csv',\n",
       " 'PUF_TRAUMA.csv',\n",
       " 'PUF_TRAUMA_LOOKUP.csv',\n",
       " 'TQP_INCLUSION.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directories for csv files\n",
    "csv_dir = 'C:/Users/micha/OneDrive - UT Health San Antonio/UTHSCSA/Trauma/TransfusionPrediction/data/PUF AY 2022/CSV'\n",
    "os.listdir(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38733bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataframe: variable_formats\n",
      "Created dataframe: ais15to05_crosswalk\n",
      "Created dataframe: aisdiagnosis\n",
      "Created dataframe: aisdiagnosis_lookup\n",
      "Created dataframe: ecode_lookup\n",
      "Created dataframe: hospitalevents\n",
      "Created dataframe: icddiagnosis\n",
      "Created dataframe: icddiagnosis_lookup\n",
      "Created dataframe: icdprocedure\n",
      "Created dataframe: icdprocedure_lookup\n",
      "Created dataframe: preexistingconditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_17040\\1041542712.py:14: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, filename), encoding='utf-8', skipinitialspace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataframe: trauma\n",
      "Created dataframe: trauma_lookup\n",
      "Created dataframe: inclusion\n"
     ]
    }
   ],
   "source": [
    "# create a pandas dataframe for each file\n",
    "\n",
    "os.listdir(csv_dir)\n",
    "\n",
    "directory = csv_dir\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Remove the first 4 characters, replace spaces with underscores, and create a dataframe name\n",
    "        df_name = filename[4:].lower().replace('.csv', '').replace(' ', '_')\n",
    "        \n",
    "        # Try different encodings and handle spaces\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(directory, filename), encoding='utf-8', skipinitialspace=True)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(os.path.join(directory, filename), encoding='latin1', skipinitialspace=True)\n",
    "        \n",
    "        # Assign the dataframe to a variable with the processed name\n",
    "        globals()[df_name] = df\n",
    "\n",
    "        print(f\"Created dataframe: {df_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97891d",
   "metadata": {},
   "source": [
    "We need to create a response variable, so we will create the variable transfusion. This will be a Yes or No for whether the patient recieved a transfusion, of any kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51361365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200411, 6)\n"
     ]
    }
   ],
   "source": [
    "# transfusions, which ICD procedure code starts with 302:\n",
    "transfusions = icdprocedure[icdprocedure['ICDPROCEDURECODE'].str.startswith('302') & icdprocedure['ICDPROCEDURECODE'].notnull()]\n",
    "\n",
    "print(transfusions.shape)\n",
    "# 200411 transfusions in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b27ee",
   "metadata": {},
   "source": [
    "Now creating a new dataframe with transfusions as the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07ae93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df: (1232956, 232)\n",
      "total number of transfusions in dataset: 109819\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the dummy variable\n",
    "trauma_transfusions = trauma.copy()\n",
    "trauma_transfusions['transfusion'] = trauma['inc_key'].isin(transfusions['Inc_Key'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(f'shape of df: {trauma_transfusions.shape}')\n",
    "print(f'total number of transfusions in dataset: {trauma_transfusions['transfusion'].sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd764195",
   "metadata": {},
   "source": [
    "Now we will decide which columns to keep. We will remove all but these:\n",
    "\n",
    "- ISS\n",
    "- AgeYears\n",
    "- SBP\n",
    "- PULSERATE\n",
    "- TEMPERATURE\n",
    "- RESPIRATORYRATE\n",
    "- PULSEOXIMETRY\n",
    "- HIGHESTACTIVATION\n",
    "- TRANSPORTMODE\n",
    "- transfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63473f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "cols_to_keep = [\n",
    "    \"ISS\",\n",
    "    \"AgeYears\",\n",
    "    \"SBP\",\n",
    "    \"PULSERATE\",\n",
    "    \"TEMPERATURE\",\n",
    "    \"RESPIRATORYRATE\",\n",
    "    \"PULSEOXIMETRY\",\n",
    "    \"HIGHESTACTIVATION\",\n",
    "    \"TRANSPORTMODE\",\n",
    "    \"transfusion\"\n",
    "]\n",
    "\n",
    "# Keep only the specified columns (and preserve order)\n",
    "trauma_transfusions = trauma_transfusions[cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c04f8",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will do imputation using KNN. First, we will see what is missing of the important columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc00038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "ISS                    3241\n",
      "AgeYears              83038\n",
      "SBP                   54617\n",
      "PULSERATE             41717\n",
      "TEMPERATURE          120495\n",
      "RESPIRATORYRATE       56133\n",
      "PULSEOXIMETRY         56310\n",
      "HIGHESTACTIVATION     15937\n",
      "TRANSPORTMODE          3919\n",
      "transfusion               0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values in dataframe: 435407\n",
      "                   missing_count  missing_percent\n",
      "ISS                         3241             0.26\n",
      "AgeYears                   83038             6.73\n",
      "SBP                        54617             4.43\n",
      "PULSERATE                  41717             3.38\n",
      "TEMPERATURE               120495             9.77\n",
      "RESPIRATORYRATE            56133             4.55\n",
      "PULSEOXIMETRY              56310             4.57\n",
      "HIGHESTACTIVATION          15937             1.29\n",
      "TRANSPORTMODE               3919             0.32\n",
      "transfusion                    0             0.00\n"
     ]
    }
   ],
   "source": [
    "# --- Missing-value summary ---\n",
    "missing_per_col = trauma_transfusions[cols_to_keep].isna().sum()       # count per column of important variables\n",
    "total_missing    = missing_per_col.sum()                  # grand total\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_per_col)\n",
    "print(f\"\\nTotal missing values in dataframe: {total_missing}\")\n",
    "\n",
    "percent_missing = (missing_per_col / len(trauma_transfusions) * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"missing_count\": missing_per_col,\n",
    "    \"missing_percent\": percent_missing\n",
    "})\n",
    "\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b49a9",
   "metadata": {},
   "source": [
    "We see 10% missing on temperature, which is tolerable. There won't be any issue in using those variables.\n",
    "\n",
    "We will now continue to impute using KNNImputer from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da725d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. Separate predictors and target\n",
    "# ------------------------------------------\n",
    "target_col = \"transfusion\"\n",
    "X = trauma_transfusions.drop(columns=[target_col]).copy()\n",
    "y = trauma_transfusions[target_col]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. Identify column types\n",
    "# ------------------------------------------\n",
    "num_cols = [\n",
    "    \"ISS\", \"AgeYears\", \"SBP\", \"PULSERATE\",\n",
    "    \"TEMPERATURE\", \"RESPIRATORYRATE\", \"PULSEOXIMETRY\"\n",
    "]\n",
    "cat_cols = [\"HIGHESTACTIVATION\", \"TRANSPORTMODE\"]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. Ordinal-encode categoricals (so KNNImputer can work)\n",
    "#    • unknown_value = -1 → keeps NaNs distinct while fitting\n",
    "# ------------------------------------------\n",
    "encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "X[cat_cols] = encoder.fit_transform(X[cat_cols])\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. Run KNN imputation (k = 5, distance-weighted)\n",
    "# ------------------------------------------\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "X_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X),\n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. Cast categorical columns back to integers → original labels\n",
    "# ------------------------------------------\n",
    "X_imputed[cat_cols] = (\n",
    "    X_imputed[cat_cols].round().astype(int)\n",
    ")\n",
    "X_imputed[cat_cols] = encoder.inverse_transform(\n",
    "    X_imputed[cat_cols]\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 6. Reassemble the full dataframe\n",
    "# ------------------------------------------\n",
    "trauma_imputed = pd.concat([X_imputed, y], axis=1)\n",
    "\n",
    "# optional sanity check\n",
    "print(trauma_imputed.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e44473",
   "metadata": {},
   "outputs": [],
   "source": [
    "trauma_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee39491",
   "metadata": {},
   "source": [
    "Imputation is done, so now we can continue to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the full imputed dataset ---\n",
    "trauma_imputed.to_csv(\"trauma_most_important.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82310393",
   "metadata": {},
   "source": [
    "We will save a small sample csv as well. This code is for a sample if needed so can be ran before the dataset has been imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1ad4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save a 15-row random sample with NO missing values ---\n",
    "clean_df = trauma_transfusions.dropna()                   # remove any rows that still contain NaNs\n",
    "assert len(clean_df) >= 15, \"Not enough complete cases to sample 15 rows.\"\n",
    "\n",
    "sample_df = clean_df.sample(n=15, random_state=42)   # reproducible sample\n",
    "sample_df.to_csv(\"trauma_most_important_sample.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trauma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
