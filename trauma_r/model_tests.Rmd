---
title: "R Notebook"
output: html_notebook
---

```{r library}
library(car)
library(tidyverse)
library(caret)
library(data.table)
library(MASS)
library(pROC)
# library(DMwR)
library(glmnet)
```



Lets get the data:

```{r data}
trauma <- fread('trauma_preprocessed_final.csv',header=TRUE)
head(trauma)
```


```{r traintestsplit}
trainIndex <- createDataPartition(trauma$transfusion, p = 0.80, list = FALSE, times = 1)

# Create training and test sets
trainData <- trauma[trainIndex, ]
testData <- trauma[-trainIndex, ]

# View the split
table(trainData$transfusion)
table(testData$transfusion)
```



```{r}
model <- glm(transfusion ~., data=trainData, family='binomial')
summary(model)
```


```{r metrics.full}
# Make predictions on the training data
pred_prob <- predict(model, type = "response")  # Predicted probabilities

# Set a threshold for classification (e.g., 0.5)
pred_class <- ifelse(pred_prob > 0.1, 1, 0)

# Create a confusion matrix
cm <- confusionMatrix(as.factor(pred_class), as.factor(trainData$transfusion),positive = "1")

# Print confusion matrix
print(cm)


# Extract values from confusion matrix
cm$table  # The confusion matrix table

# Sensitivity (Recall) = TP / (TP + FN)
sensitivity <- cm$byClass['Sensitivity']

# Specificity = TN / (TN + FP)
specificity <- cm$byClass['Specificity']

# Accuracy = (TP + TN) / (TP + TN + FP + FN)
accuracy <- cm$overall['Accuracy']

# Precision = TP / (TP + FP)
precision <- cm$byClass['Precision']

# Print the metrics
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")

# Calculate the ROC curve
roc_curve <- roc(trainData$transfusion, pred_prob)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Display the AUC (Area Under the Curve)
auc(roc_curve)

```


```{r}
# Get names of all predictor variables in the dataset
predictors <- names(trainData)[!names(trainData) %in% "transfusion"]

# Create the full formula
full_formula <- as.formula(paste("transfusion ~", paste(predictors, collapse = " + ")))
```



```{r stepwiseregression}
# Fit an initial logistic regression model with no predictors (only intercept)
initial_model <- glm(transfusion ~ 1, data = trainData, family = binomial())

# Perform stepwise selection using AIC
stepwise_model <- stepAIC(initial_model, 
                           scope = list(lower = ~1, upper = full_formula), 
                           direction = "both", 
                           trace = 1)

# View the summary of the selected model
summary(stepwise_model)

```


### Outcome for smaller model:
get some stuff you expect. HR, SBP, temp, etc. some results here for further reference:

Coefficients:
                              Estimate Std. Error z value Pr(>|z|)    
(Intercept)                   -3.63541    0.26691 -13.620  < 2e-16 ***
scaler__ISS                    0.65141    0.03606  18.066  < 2e-16 ***
label__HIGHESTACTIVATION      -0.99959    0.08919 -11.207  < 2e-16 ***
scaler__AgeYears               0.46731    0.04398  10.627  < 2e-16 ***
scaler__SBP                   -0.41280    0.03665 -11.264  < 2e-16 ***
scaler__PULSERATE              0.27636    0.03537   7.814 5.55e-15 ***
label__TRANSPORTMODE          -0.19205    0.04079  -4.708 2.50e-06 ***
label__INTERFACILITYTRANSFER   0.58856    0.10147   5.800 6.62e-09 ***
label__SUPPLEMENTALOXYGEN      0.40580    0.09388   4.322 1.54e-05 ***
scaler__PULSEOXIMETRY          0.08618    0.02785   3.094 0.001975 ** 
label__PMGCSQ_NA               0.35234    0.08668   4.065 4.80e-05 ***
label__TM_GROUNDAMBULANCE      0.34895    0.11175   3.123 0.001792 ** 
label__AIRBAG_DEPLOYED_NA      0.23786    0.11394   2.088 0.036840 *  
label__DRGSCR_METHAMPHETAMINE -1.08953    0.37938  -2.872 0.004080 ** 
label__Bedsize                 0.12432    0.04019   3.094 0.001976 ** 
onehot__SEX_2.0                0.28839    0.08374   3.444 0.000574 ***
scaler__HEIGHT                 0.16017    0.04802   3.335 0.000852 ***
label__RACEOTHER               0.34029    0.12552   2.711 0.006708 ** 
onehot__TBIMIDLINESHIFT_1.0    0.43476    0.18271   2.379 0.017338 *  
scaler__TEMPERATURE           -0.06191    0.02765  -2.239 0.025159 *  
label__TBIPUPILLARYRESPONSE   -0.27309    0.11153  -2.448 0.014346 *  
label__PMGCSQ_INTUBATED        0.36615    0.17440   2.100 0.035772 *  
label__STATEDESIGNATION        0.06862    0.03602   1.905 0.056772 .  
label__HOMERESIDENCE_NA        0.31359    0.17093   1.835 0.066561 .  
label__RACE_UK                 0.38117    0.22439   1.699 0.089378 .  
label__AIRBAG_DEPLOYED_SIDE   -0.48478    0.26671  -1.818 0.069119 .  
scaler__RESPIRATORYRATE        0.05282    0.03135   1.685 0.092049 .  
label__AIRBAG_NOTDEPLOYED     -0.49716    0.33476  -1.485 0.137510    
onehot__TEACHINGSTATUS_6.0     0.14503    0.09830   1.475 0.140118   


```{r metrics}
# Make predictions on the training data
pred_prob <- predict(stepwise_model, type = "response")  # Predicted probabilities

# Set a threshold for classification (e.g., 0.5)
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# Create a confusion matrix
cm <- confusionMatrix(as.factor(pred_class), as.factor(trainData$transfusion),positive = "1")

# Print confusion matrix
print(cm)


# Extract values from confusion matrix
cm$table  # The confusion matrix table

# Sensitivity (Recall) = TP / (TP + FN)
sensitivity <- cm$byClass['Sensitivity']

# Specificity = TN / (TN + FP)
specificity <- cm$byClass['Specificity']

# Accuracy = (TP + TN) / (TP + TN + FP + FN)
accuracy <- cm$overall['Accuracy']

# Precision = TP / (TP + FP)
precision <- cm$byClass['Precision']

# Print the metrics
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")

# Calculate the ROC curve
roc_curve <- roc(trainData$transfusion, pred_prob)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Display the AUC (Area Under the Curve)
auc(roc_curve)

```



```{r savemodel}
# Save the model as an RDS file
saveRDS(stepwise_model, file = "stepwise_model.rds")

```


```{r loadmodel}
# Load the model from the RDS file
stepwise_model <- readRDS("stepwise_model.rds")

# Use the model
summary(stepwise_model)

```




```{r ridge}
library(glmnet)

# Prepare data for glmnet
x <- model.matrix(transfusion ~ ., data = trainData)[, -1]
y <- trainData$transfusion

# Fit a ridge regression model (alpha = 0 for ridge)
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0)


# Use cross-validation to find the best lambda
cv_ridge <- cv.glmnet(x, y, family = "binomial", alpha = 0)
best_lambda <- cv_ridge$lambda.min  # The lambda that gives the minimum mean cross-validated error

# Extract coefficients at the best lambda
ridge_coefs <- coef(ridge_model, s = best_lambda)
print(ridge_coefs)

# Summary of cross-validation results
plot(cv_ridge)
cat("Best lambda:", best_lambda, "\n")
cat("Cross-validated error at best lambda:", min(cv_ridge$cvm), "\n")


```

```{r ridgetest}
# Make predictions on the test data
test_x <- model.matrix(transfusion ~ ., data = testData)[, -1]
pred_prob <- predict(ridge_model, s = best_lambda, newx = test_x, type = "response")
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# Confusion matrix and metrics
conf_matrix <- confusionMatrix(as.factor(pred_class), as.factor(testData$transfusion), positive = "1", mode='everything')
print(conf_matrix)

```


```{r saveridge}
# Save the model as an RDS file
saveRDS(cv_ridge, file = "cv_ridge.rds")

```


```{r loadridge}
# Load the model from the RDS file
cv_ridge <- readRDS("cv_ridge.rds")

# Use the model
summary(cv_ridge)

```



# Oversampling done below
Using SMOTE.

```{r oversampling}
# library(DMwR)
library(smotefamily)

# Separate features and target variable
x <- trainData[, -81]
y <- trainData$transfusion

# Apply SMOTE
trainData_smote <- SMOTE(x, y, K = 5, dup_size = 10)

table(trainData_smote$data$class)
table(trainData$transfusion)

```



```{r smoteridge}
# Prepare data for glmnet
x <- model.matrix(class ~ ., data = trainData_smote$data)[, -1]
y <- trainData_smote$data$class

# Fit a ridge regression model (alpha = 0 for ridge)
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0)


# Use cross-validation to find the best lambda
cv_ridge <- cv.glmnet(x, y, family = "binomial", alpha = 0)
best_lambda <- cv_ridge$lambda.1se  # The lambda that gives the minimum mean cross-validated error

# Extract coefficients at the best lambda
ridge_coefs <- coef(ridge_model, s = best_lambda)
print(ridge_coefs)

# Summary of cross-validation results
plot(cv_ridge)
cat("Best lambda:", best_lambda, "\n")
cat("Cross-validated error at best lambda:", min(cv_ridge$cvm), "\n")

```


```{r smoteridgetest}
# Make predictions on the test data
test_x <- model.matrix(transfusion ~ ., data = testData)[, -1]
pred_prob <- predict(ridge_model, s = best_lambda, newx = test_x, type = "response")
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# Confusion matrix and metrics
conf_matrix <- confusionMatrix(as.factor(pred_class), as.factor(testData$transfusion), positive = "1", mode='everything')
print(conf_matrix)

```

```{r stepwiseregressionSMOTE}
# Fit an initial logistic regression model with no predictors (only intercept)
initial_model <- glm(class ~ 1, data = trainData_smote$data, family = binomial())

# Perform stepwise selection using AIC
stepwise_model <- stepAIC(initial_model, 
                           scope = list(lower = ~1, upper = full_formula), 
                           direction = "both", 
                           trace = 1)

# View the summary of the selected model
summary(stepwise_model)

```

```{r metricsSMOTE}
# Make predictions on the training data
pred_prob <- predict(stepwise_model, type = "response")  # Predicted probabilities

# Set a threshold for classification (e.g., 0.5)
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# Create a confusion matrix
cm <- confusionMatrix(as.factor(pred_class), as.factor(trainData$transfusion),positive = "1")

# Print confusion matrix
print(cm)


# Extract values from confusion matrix
cm$table  # The confusion matrix table

# Sensitivity (Recall) = TP / (TP + FN)
sensitivity <- cm$byClass['Sensitivity']

# Specificity = TN / (TN + FP)
specificity <- cm$byClass['Specificity']

# Accuracy = (TP + TN) / (TP + TN + FP + FN)
accuracy <- cm$overall['Accuracy']

# Precision = TP / (TP + FP)
precision <- cm$byClass['Precision']

# Print the metrics
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")

# Calculate the ROC curve
roc_curve <- roc(trainData$transfusion, pred_prob)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Display the AUC (Area Under the Curve)
auc(roc_curve)

```

```{r saveSMOTE}
# Save the model as an RDS file
saveRDS(stepwise_model, file = "stepwise_model_smote.rds")

```


```{r loadSMOTE}
# Load the model from the RDS file
stepwise_model_smote <- readRDS("stepwise_model_smote.rds")

# Use the model
summary(cv_ridge)

```
